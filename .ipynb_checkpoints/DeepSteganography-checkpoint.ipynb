{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports necessary libraries and modules\n",
    "from itertools import islice\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch import utils\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import os \n",
    "import pickle\n",
    "from torchvision import datasets, utils\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToPILImage\n",
    "from random import shuffle\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hamza_ELF\\anaconda3\\envs\\AI_labs\\DeepSteg\n"
     ]
    }
   ],
   "source": [
    "# Directory path\n",
    "# os.chdir(\"..\")\n",
    "cwd = os.getcwd()+'/input'\n",
    "\n",
    "# Hyper Parameters\n",
    "num_epochs = 3\n",
    "batch_size = 2\n",
    "learning_rate = 0.0001\n",
    "beta = 1\n",
    "\n",
    "# Mean and std deviation of imagenet dataset. Source: http://cs231n.stanford.edu/reports/2017/pdfs/101.pdf\n",
    "std = [0.229, 0.224, 0.225]\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "\n",
    "# TODO: Define train, validation and models\n",
    "MODELS_PATH = os.getcwd()+'/output/models/'\n",
    "# TRAIN_PATH = cwd+'/train/'\n",
    "# VALID_PATH = cwd+'/valid/'\n",
    "VALID_PATH = cwd+'/sample/valid/'\n",
    "TRAIN_PATH = cwd+'/sample/train/'\n",
    "TEST_PATH = cwd+'/test/'\n",
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "if not os.path.exists(MODELS_PATH): os.mkdir(MODELS_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set of useful functions we are going to need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customized_loss(S_prime, C_prime, S, C, B):\n",
    "    ''' Calculates loss specified on the paper.'''\n",
    "    \n",
    "    loss_cover = torch.nn.functional.mse_loss(C_prime, C)\n",
    "    loss_secret = torch.nn.functional.mse_loss(S_prime, S)\n",
    "    loss_all = loss_cover + B * loss_secret\n",
    "    return loss_all, loss_cover, loss_secret\n",
    "\n",
    "def denormalize(image, std, mean):\n",
    "    ''' Denormalizes a tensor of images.'''\n",
    "\n",
    "    for t in range(3):\n",
    "        image[t, :, :] = (image[t, :, :] * std[t]) + mean[t]\n",
    "    return image\n",
    "\n",
    "def imshow(img, idx, learning_rate, beta):\n",
    "    '''Prints out an image given in tensor format.'''\n",
    "    \n",
    "    img = denormalize(img, std, mean)\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.title('Example '+str(idx)+', lr='+str(learning_rate)+', B='+str(beta))\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def gaussian(tensor, mean=0, stddev=0.1):\n",
    "    '''Adds random noise to a tensor.'''\n",
    "    \n",
    "    noise = torch.nn.init.normal(torch.Tensor(tensor.size()), 0, 0.1)\n",
    "    return Variable(tensor + noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The author used 3x3, 4x4 and 5x5 each for the first four layers and the concatenated them and passed them to the final layer. \n",
    "\n",
    "This architecture was replicated exactly in each of the layers. Output of PrepNetwork (secret image preapred to merge with cover) is concatenated to the cover and fed into the hidding network. The hidding network hides the secret image in the PrepNetwork's output and returns the hidden image. This is fed into the Reveal network to output the message, that should be close to the secret image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparation Network (2 conv layers)\n",
    "class PrepNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PrepNetwork, self).__init__()\n",
    "        self.initialP3 = nn.Sequential(\n",
    "            nn.Conv2d(3, 50, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(50, 50, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(50, 50, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(50, 50, kernel_size=3, padding=1),\n",
    "            nn.ReLU())\n",
    "        self.initialP4 = nn.Sequential(\n",
    "            nn.Conv2d(3, 50, kernel_size=4, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(50, 50, kernel_size=4, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(50, 50, kernel_size=4, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(50, 50, kernel_size=4, padding=2),\n",
    "            nn.ReLU())\n",
    "        self.initialP5 = nn.Sequential(\n",
    "            nn.Conv2d(3, 50, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(50, 50, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(50, 50, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(50, 50, kernel_size=5, padding=2),\n",
    "            nn.ReLU())\n",
    "        self.finalP3 = nn.Sequential(\n",
    "            nn.Conv2d(150, 50, kernel_size=3, padding=1),\n",
    "            nn.ReLU())\n",
    "        self.finalP4 = nn.Sequential(\n",
    "            nn.Conv2d(150, 50, kernel_size=4, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(50, 50, kernel_size=4, padding=2),\n",
    "            nn.ReLU())\n",
    "        self.finalP5 = nn.Sequential(\n",
    "            nn.Conv2d(150, 50, kernel_size=5, padding=2),\n",
    "            nn.ReLU())\n",
    "\n",
    "    def forward(self, p):\n",
    "        p1 = self.initialP3(p)\n",
    "        p2 = self.initialP4(p)\n",
    "        p3 = self.initialP5(p)\n",
    "        mid = torch.cat((p1, p2, p3), 1)\n",
    "        p4 = self.finalP3(mid)\n",
    "        p5 = self.finalP4(mid)\n",
    "        p6 = self.finalP5(mid)\n",
    "        out = torch.cat((p4, p5, p6), 1)\n",
    "        return out\n",
    "\n",
    "# Hiding Network (5 conv layers)\n",
    "class HidingNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HidingNetwork, self).__init__()\n",
    "        self.initialH3 = nn.Sequential(\n",
    "            nn.Conv2d(153, 50, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(50, 50, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(50, 50, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(50, 50, kernel_size=3, padding=1),\n",
    "            nn.ReLU())\n",
    "        self.initialH4 = nn.Sequential(\n",
    "            nn.Conv2d(153, 50, kernel_size=4, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(50, 50, kernel_size=4, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(50, 50, kernel_size=4, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(50, 50, kernel_size=4, padding=2),\n",
    "            nn.ReLU())\n",
    "        self.initialH5 = nn.Sequential(\n",
    "            nn.Conv2d(153, 50, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(50, 50, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(50, 50, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(50, 50, kernel_size=5, padding=2),\n",
    "            nn.ReLU())\n",
    "        self.finalH3 = nn.Sequential(\n",
    "            nn.Conv2d(150, 50, kernel_size=3, padding=1),\n",
    "            nn.ReLU())\n",
    "        self.finalH4 = nn.Sequential(\n",
    "            nn.Conv2d(150, 50, kernel_size=4, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(50, 50, kernel_size=4, padding=2),\n",
    "            nn.ReLU())\n",
    "        self.finalH5 = nn.Sequential(\n",
    "            nn.Conv2d(150, 50, kernel_size=5, padding=2),\n",
    "            nn.ReLU())\n",
    "        self.finalH = nn.Sequential(\n",
    "            nn.Conv2d(150, 3, kernel_size=1, padding=0))\n",
    "        \n",
    "    def forward(self, h):\n",
    "        h1 = self.initialH3(h)\n",
    "        h2 = self.initialH4(h)\n",
    "        h3 = self.initialH5(h)\n",
    "        mid = torch.cat((h1, h2, h3), 1)\n",
    "        h4 = self.finalH3(mid)\n",
    "        h5 = self.finalH4(mid)\n",
    "        h6 = self.finalH5(mid)\n",
    "        mid2 = torch.cat((h4, h5, h6), 1)\n",
    "        out = self.finalH(mid2)\n",
    "        out_noise = gaussian(out.data, 0, 0.1)\n",
    "        return out, out_noise\n",
    "\n",
    "# Reveal Network (2 conv layers)\n",
    "class RevealNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RevealNetwork, self).__init__()\n",
    "        self.initialR3 = nn.Sequential(\n",
    "            nn.Conv2d(3, 50, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(50, 50, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(50, 50, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(50, 50, kernel_size=3, padding=1),\n",
    "            nn.ReLU())\n",
    "        self.initialR4 = nn.Sequential(\n",
    "            nn.Conv2d(3, 50, kernel_size=4, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(50, 50, kernel_size=4, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(50, 50, kernel_size=4, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(50, 50, kernel_size=4, padding=2),\n",
    "            nn.ReLU())\n",
    "        self.initialR5 = nn.Sequential(\n",
    "            nn.Conv2d(3, 50, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(50, 50, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(50, 50, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(50, 50, kernel_size=5, padding=2),\n",
    "            nn.ReLU())\n",
    "        self.finalR3 = nn.Sequential(\n",
    "            nn.Conv2d(150, 50, kernel_size=3, padding=1),\n",
    "            nn.ReLU())\n",
    "        self.finalR4 = nn.Sequential(\n",
    "            nn.Conv2d(150, 50, kernel_size=4, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(50, 50, kernel_size=4, padding=2),\n",
    "            nn.ReLU())\n",
    "        self.finalR5 = nn.Sequential(\n",
    "            nn.Conv2d(150, 50, kernel_size=5, padding=2),\n",
    "            nn.ReLU())\n",
    "        self.finalR = nn.Sequential(\n",
    "            nn.Conv2d(150, 3, kernel_size=1, padding=0))\n",
    "\n",
    "    def forward(self, r):\n",
    "        r1 = self.initialR3(r)\n",
    "        r2 = self.initialR4(r)\n",
    "        r3 = self.initialR5(r)\n",
    "        mid = torch.cat((r1, r2, r3), 1)\n",
    "        r4 = self.finalR3(mid)\n",
    "        r5 = self.finalR4(mid)\n",
    "        r6 = self.finalR5(mid)\n",
    "        mid2 = torch.cat((r4, r5, r6), 1)\n",
    "        out = self.finalR(mid2)\n",
    "        return out\n",
    "\n",
    "# Join three networks in one module\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.m1 = PrepNetwork()\n",
    "        self.m2 = HidingNetwork()\n",
    "        self.m3 = RevealNetwork()\n",
    "\n",
    "    def forward(self, secret, cover):\n",
    "        x_1 = self.m1(secret)\n",
    "        mid = torch.cat((x_1, cover), 1)\n",
    "        x_2, x_2_noise = self.m2(mid)\n",
    "        x_3 = self.m3(x_2_noise)\n",
    "        return x_2, x_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates net object\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create loaders for normalized training, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hamza_ELF\\anaconda3\\envs\\AI_labs\\lib\\site-packages\\torchvision\\transforms\\transforms.py:279: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  warnings.warn(\"The use of the transforms.Scale transform is deprecated, \" +\n"
     ]
    }
   ],
   "source": [
    "# Creates training set\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.ImageFolder(\n",
    "        TRAIN_PATH,\n",
    "        transforms.Compose([\n",
    "        transforms.Scale(256),\n",
    "        transforms.RandomCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean,\n",
    "        std=std)\n",
    "        ])), batch_size=batch_size, num_workers=1, \n",
    "        pin_memory=True, shuffle=True, drop_last=True)\n",
    "\n",
    "# Creates test set\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.ImageFolder(\n",
    "        TEST_PATH, \n",
    "        transforms.Compose([\n",
    "        transforms.Scale(256),\n",
    "        transforms.RandomCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean,\n",
    "        std=std)\n",
    "        ])), batch_size=2, num_workers=1, \n",
    "        pin_memory=True, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train the model and validate it, saving the best model. We use Adam as an optimizer as the paper specifies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_loader, beta, learning_rate):\n",
    "    \n",
    "    # Save optimizer\n",
    "    optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    \n",
    "    loss_history = []\n",
    "    # Iterate over batches performing forward and backward passes\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # Train mode\n",
    "        net.train()\n",
    "        \n",
    "        train_losses = []\n",
    "        # Train one epoch\n",
    "        for idx, train_batch in enumerate(train_loader):\n",
    "\n",
    "            data, _  = train_batch\n",
    "\n",
    "            # Saves secret images and secret covers\n",
    "            train_covers = data[:len(data)//2]\n",
    "            train_secrets = data[len(data)//2:]\n",
    "            \n",
    "            # Creates variable from secret and cover images\n",
    "            train_secrets = Variable(train_secrets, requires_grad=False)\n",
    "            train_covers = Variable(train_covers, requires_grad=False)\n",
    "\n",
    "            # Forward + Backward + Optimize\n",
    "            optimizer.zero_grad()\n",
    "            train_hidden, train_output = net(train_secrets, train_covers)\n",
    "\n",
    "            # Calculate loss and perform backprop\n",
    "            train_loss, train_loss_cover, train_loss_secret = customized_loss(train_output, train_hidden, train_secrets, train_covers, beta)\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "            # Saves training loss\n",
    "            train_losses.append(train_loss.data)\n",
    "            loss_history.append(train_loss.data)\n",
    "            \n",
    "            # Prints mini-batch losses\n",
    "            print('Training: Batch {0}/{1}. Loss of {2:.4f}, cover loss of {3:.4f}, secret loss of {4:.4f}'.format(idx+1, len(train_loader), train_loss.data[0], train_loss_cover.data[0], train_loss_secret.data[0]))\n",
    "    \n",
    "        torch.save(net.state_dict(), MODELS_PATH+'Epoch N{}.pkl'.format(epoch+1))\n",
    "        \n",
    "        mean_train_loss = np.mean(train_losses)\n",
    "    \n",
    "        # Prints epoch average loss\n",
    "        print ('Epoch [{0}/{1}], Average_loss: {2:.4f}'.format(\n",
    "                epoch+1, num_epochs, mean_train_loss))\n",
    "    \n",
    "    return net, mean_train_loss, loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hamza_ELF\\anaconda3\\envs\\AI_labs\\lib\\site-packages\\torch\\cuda\\__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  ..\\c10\\cuda\\CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "<ipython-input-12-723a443b100a>:29: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "  noise = torch.nn.init.normal(torch.Tensor(tensor.size()), 0, 0.1)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-7e8fb043b909>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_train_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_history\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-16-fc37f827be86>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(train_loader, beta, learning_rate)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[1;31m# Saves training loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m             \u001b[0mtrain_losses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m             \u001b[0mloss_history\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number"
     ]
    }
   ],
   "source": [
    "net, mean_train_loss, loss_history = train_model(train_loader, beta, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss through epochs\n",
    "plt.plot(loss_history)\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Batch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test the model and print out a few images so we can visually see how good a job the model did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net.load_state_dict(torch.load(MODELS_PATH+'Epoch N4.pkl'))\n",
    "\n",
    "# Switch to evaluate mode\n",
    "net.eval()\n",
    "\n",
    "test_losses = []\n",
    "# Show images\n",
    "for idx, test_batch in enumerate(test_loader):\n",
    "     # Saves images\n",
    "    data, _ = test_batch\n",
    "\n",
    "    # Saves secret images and secret covers\n",
    "    test_secret = data[:len(data)//2]\n",
    "    test_cover = data[len(data)//2:]\n",
    "\n",
    "    # Creates variable from secret and cover images\n",
    "    test_secret = Variable(test_secret, volatile=True)\n",
    "    test_cover = Variable(test_cover, volatile=True)\n",
    "\n",
    "    # Compute output\n",
    "    test_hidden, test_output = net(test_secret, test_cover)\n",
    "    \n",
    "    # Calculate loss\n",
    "    test_loss, loss_cover, loss_secret = customized_loss(test_output, test_hidden, test_secret, test_cover, beta)\n",
    "    \n",
    "#     diff_S, diff_C = np.abs(np.array(test_output.data[0]) - np.array(test_secret.data[0])), np.abs(np.array(test_hidden.data[0]) - np.array(test_cover.data[0]))\n",
    "    \n",
    "#     print (diff_S, diff_C)\n",
    "    \n",
    "    if idx in [1,2,3,4]:\n",
    "        print ('Total loss: {:.2f} \\nLoss on secret: {:.2f} \\nLoss on cover: {:.2f}'.format(test_loss.data[0], loss_secret.data[0], loss_cover.data[0]))\n",
    "\n",
    "        # Creates img tensor\n",
    "        imgs = [test_secret.data, test_output.data, test_cover.data, test_hidden.data]\n",
    "        imgs_tsor = torch.cat(imgs, 0)\n",
    "\n",
    "        # Prints Images\n",
    "        imshow(utils.make_grid(imgs_tsor), idx+1, learning_rate=learning_rate, beta=beta)\n",
    "        \n",
    "    test_losses.append(test_loss.data[0])\n",
    "        \n",
    "mean_test_loss = np.mean(test_losses)\n",
    "\n",
    "print ('Average loss on test set: {:.2f}'.format(mean_test_loss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
